---
title: Multimodal signal processing and learning for wearables

event: AI UK Fringe 2023

location: Online

summary: An interactive, online workshop providing an introduction to the fundamentals of biomedical signal processing and learning for wearable signals of multiple modalities.

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2023-03-15T10:00:00Z"
date_end: "2022-03-15T12:00:00Z"
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: "2017-01-01T00:00:00Z"

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image: 
  caption: Photo by <a href="https://unsplash.com/fr/@lukechesser?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Luke Chesser</a> on <a href="https://unsplash.com/photos/rCOWMC8qf8A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
  focal_point: ""
  placement: 1
  preview_only: false
  
authors: [admin]
tags: [signal processing, open research, photoplethysmography, electrocardiogram, blood pressure]

# Is this a featured talk? (true/false)
featured: true

links:
- icon: twitter
  icon_pack: fab
  name: Follow
  url: https://twitter.com/PeterHCharlton
- name: Registration
  url: https://turing-uk.zoom.us/meeting/register/tJMofuiprjwiHdw3j6auc_oeuyXjoGyjyoYY
url_pdf: "https://zenodo.org/record/7734871/files/multimodal_sig_proc_2023.pdf?download=1"
url_slides: "https://doi.org/10.5281/zenodo.7734870"
url_video: "https://www.youtube.com/watch?v=MANsp-qoCgg"

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
- understanding ppg
---

### Workshop Synopsis

An interactive, online workshop providing an introduction to the fundamentals of biomedical signal processing and learning for wearable signals of multiple modalities.

Digital wearable devices have great potential to improve health and wellbeing by monitoring physiology in daily life. A key challenge is making wearable data as rich and accurate as possible. The aim of this workshop is to equip attendees with knowledge and skills in processing wearable data, benefiting researchers in academia, device designers in industry, and ultimately the millions of people who use wearables to monitor their health and fitness.

The workshop will consist of three parts:
- Participants will be introduced to the signals measured by wearables, including photoplethysmogram and electrocardiogram signals.
- Participants will learn fundamental techniques for processing wearable signals through interactive tutorials.
- Participants will gain hands-on experience of signal processing and machine learning with wearable data through a group exercise, applying data analysis to real-world problems.

The workshop will use pre-prepared teaching materials consisting of online Jupyter notebooks running Python code on the cloud, so no installation is required on participants' computers. The teaching materials are designed to be highly accessible to the non-specialist, while also providing opportunity for people with experience in the field to explore the topic more deeply.

### Registration

The event will be held on Zoom:

{{< cta cta_text="Register here" cta_link="https://turing-uk.zoom.us/meeting/register/tJMofuiprjwiHdw3j6auc_oeuyXjoGyjyoYY" cta_new_tab="true" >}}

### Organisers

This event is co-organised by:
- The [Department of Public Health and Primary Care](https://www.phpc.cam.ac.uk/) at the University of Cambridge
- [Turing's meta-learning for multimodal data interest group](https://www.turing.ac.uk/research/interest-groups/meta-learning-multimodal-data)

### Turing's meta-learning for multimodal data interest group

This Interest Group, part of The Alan Turing Institute, brings together machine learning researchers, data scientists, and domain experts from diverse backgrounds, career stages, and disciplines to develop algorithms and tools that transfer knowledge across tasks and domains to improve the performance of learning algorithms on data of multiple modalities in real-world applications. See [here](https://www.turing.ac.uk/research/interest-groups/meta-learning-multimodal-data) for further details of the group's work. If you would like to sign-up and join the group then see [here](https://forms.office.com/Pages/ResponsePage.aspx?id=p_SVQ1XklU-Knx-672OE-eUxyOQjGdZIurmvwym_4o5UOFhHNkY5WU1RVlczMjNWUVdYTDFDME1VNS4u).

### AIUK 2023

This event is part of AI UK 2023. The Alan Turing Institute's national showcase of data science, machine learning and artificial intelligence research and innovation.

At a series of events between 6 - 31 March 2023, AI UK Fringe brings together leaders in academia from across the UK's AI ecosystem to demonstrate, exhibit and update on their ground-breaking work.

Examining the current and future landscapes of data science and AI in real-world settings, leadings minds discuss solutions to the most pressing concerns of our times, from environmental sustainability and health and life sciences to national security, defence and a data-driven economy.

We're excited to be part of AI UK Fringe this March and can't wait for you to join our community and contribute to key conversations.

Find out more about AI UK at [ai-uk.turing.ac.uk](ai-uk.turing.ac.uk)

### Accompanying Resources

The resources used in this workshop are available [here](https://peterhcharlton.github.io/bsp-book/).
